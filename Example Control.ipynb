{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo environment\n",
    "\n",
    "This notebook will be used as an introduction to the control and image constructs available within the demo environment of both the robot interfaces and the camera interfaces.\n",
    "\n",
    "We will cover the steps necessary to connect to and control the robot while also collecting image data from the cameras mounted around and on the robotic arm.\n",
    "\n",
    "## Camera Access\n",
    "\n",
    "In this demo we'll be utilizing Intel's [RealSense D435i](https://www.intelrealsense.com/depth-camera-d435i/) for use with out robotic arm. We'll not only want to view these images, but we'll want to collect them as we perform tasks, as well. There any many use cases and approaches one can take when peforming tasks using robotics arms such as these that span the areas of standard supervised, unsupervised, and reinforcement learning. For this reason there will likely be a few combinations of data collection that we may want to employ.\n",
    "\n",
    "We will start with building the software constructs necessary to view and collect data from the Intel RealSense camera that is connected to the arm of our robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from ipywidgets import Image, HBox\n",
    "import IPython\n",
    "import PIL.Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "import math\n",
    "import traitlets\n",
    "\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "class Camera(traitlets.HasTraits): \n",
    "    \n",
    "    value = traitlets.Any()\n",
    "    running = traitlets.Bool(default_value=False)\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Camera, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.camera_serial_num = None\n",
    "        \n",
    "        # Camera pipelines\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        self.config.enable_device(self.cam_serial_num)\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "        self.pipeline.start(self.config)\n",
    "        self._running = False\n",
    "        \n",
    "        self.value = None\n",
    "    \n",
    "    def stream(self):\n",
    "        while True:\n",
    "            self.frames = self.pipeline.wait_for_frames()\n",
    "            self.depth_frame = self.frames.get_depth_frame()\n",
    "            self.color_frame = self.frames.get_color_frame()\n",
    "            depth_image = np.asanyarray(self.depth_frame.get_data())\n",
    "            color_image = np.asanyarray(self.color_frame.get_data())\n",
    "\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.3), cv2.COLORMAP_JET)\n",
    "\n",
    "            self.value = np.hstack((color_image, depth_colormap))\n",
    "    \n",
    "    @traitlets.observe('running')\n",
    "    def view_camera(self, change):\n",
    "        if change['new'] and not change['old']:\n",
    "            self._running = True\n",
    "            thread = threading.Thread(target=self.stream)\n",
    "            thread.start()\n",
    "        if change['old'] and not change['new']:\n",
    "            self._running = False\n",
    "            # join thread to kill it\n",
    "            self.thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_1 = Camera()\n",
    "cam_1.camera_serial_num = \n",
    "image_widget_1 = Image(format='jpeg')\n",
    "\n",
    "def update_image(change):\n",
    "    image = change['new']\n",
    "    image_widget_1.value = bgr8_to_jpeg(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_1.running = True\n",
    "cam_1.observe(update_image, names='value')\n",
    "\n",
    "camera_link_1 = traitlets.dlink((cam_1, 'value'), (image_widget_1, 'value'), transform=bgr8_to_jpeg)\n",
    "display(image_widget_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_2 = Camera()\n",
    "image_widget_2 = Image(format='jpeg')\n",
    "\n",
    "def update_image_2(change):\n",
    "    image = change['new']\n",
    "    image_widget_2.value = bgr8_to_jpeg(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robotic Arm Access\n",
    "\n",
    "The arm that we are utilizing in this demo is the [ufactory xarm](https://www.xarm.cc/). The company is generous enough to provide an open source python SDK for development against the platform. We will be utilizing this SDK heavily in this demo. It is assumed that the controller being used (in our case an Ubuntu 18.04) already has this SDK installed. If it does not, please follow the installation instructions found [here](https://github.com/xArm-Developer/xArm-Python-SDK#installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xarm.wrapper import XArmAPI\n",
    "\n",
    "arm = XArmAPI('192.168.1.244')\n",
    "arm.motion_enable(enable=True)\n",
    "arm.set_mode(0)\n",
    "arm.set_state(state=0)\n",
    "speed = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm.set_servo_angle(angle=[0, 0, -20, -10, 0], speed=speed, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyrealsense2.device: Intel RealSense D435 (S/N: 937422071477)>\n"
     ]
    }
   ],
   "source": [
    "ctx = rs.context()\n",
    "for d in ctx.devices:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
